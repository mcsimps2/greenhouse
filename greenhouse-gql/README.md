# Ivy Clinicians GraphQL API

## Setup
First, clone this repository. After you have done so, run the following command to make scripts executable.
```shell
chmod +x commands/*
```

From [Github Secrets](https://github.com/ivyclinicians/ivyclinicians-graphql/settings/secrets/actions), copy the
following secrets into the corresponding files.
 - `LOCAL_SERVICE_ACCOUNT` into `web/service_account.json`
 - `ENV_WEB_DEV` into `.env.web_dev`
 - `ENV_DB_DEV` into `.env.db_dev`
 - `ENV_HASURA_DEV` into `.env.hasura_dev`

In `.env.web_dev`, add a new line for the environment variable `DEVELOPER_EMAIL=<your_company_email>`. This will be
used for seed data.

Build the Docker containers by running
```shell
docker-compose build
```

Start the containers by running
```shell
docker-compose up
```

Alternatively, to hide logs from Hasura and PostgreSQL, you can attach to just the `web` container.
```shell
docker-compose up --attach web
```

To initialize the database, open up a new terminal window and run the following sequence of commands.
```shell
# Open a shell into the web Docker container
docker-compose exec web sh

flask initdb

# The above command is equivalent to the following

# Run migrations
# flask db upgrade
# Set up the database with important data (e.g. list of residencies in the US)
# flask setupdb
# Seed data for local development
# flask seed
```

Then initialize Hasura by executing the import script. 
```shell
./commands/importhasura
```

At this point, everything should be up and running.


## Project Overview

### Folder Structure
The project is broken down based on services.
```text
 - /commands  # Helper scripts
 - /database  # PostgreSQL
 - /graphql   # Hasura
 - /web       # Flask application
```

The Flask application is architected into four primary segments - controllers, services, models, and schemas.

For traditional REST routes, controllers are responsible for defining the Flask route, parsing the Flask request
(deserialization), and returning the Flask response (serialization).  Authentication and authorization lives at the
controller layer since controllers have access to the JWT on each request.  Controllers should be the only modules that
are dependent and aware of Flask.

Controllers hand off business logic to the services layer.  The models layer simply defines the database schema.  In
this frame of reference, services and models are completely agnostic to the HTTP framework being used.  We could use
them in Flask, FastAPI, `http.server`, etc...

For GraphQL functionality, controllers are instead replaced by schemas, but their function is identical. We write
GraphQL queries and mutations using Graphene.  This is not to be confused with CRUD operations that are provided
by Hasura's GraphQL interface.  The Graphene operations are involved when there is a requirement that Hasura cannot
handle, e.g. JWT authentication.

### Code Quality
Use `black` to format code before you commit changes.
```shell
docker-compose exec web sh
black .
```

In the future, we will also use `pylint` as well and enforce these checks as part of the CICD pipeline.

## Database
### Database Frontends
After you have initialized the database, you can run SQL statements against it by either using a tool like pgAdmin 
or using the `psql` command, available as
```shell
./commands/pgshell
```

### Resetting the Database
You can reset the database by dropping the corresponding Docker containers and volumes and repeating the steps above.
Don't forget to re-import the Hasura metadata since it is dropped when the database is deleted.
```shell
docker-compose down
# Repeat the steps above to initialize the database starting with docker-compose up
```

### Alembic Migrations
If you've made changes to the SQLAclhemy models, you can use Alembic to generate a migration that will be applied in
production during a release. Note that Alembic can only detect certain changes to SQLAclhemy models, so it is up to the
developer to ensure that all migration commands are recorded.
```shell
# Start a shell into the Docker container
docker-compose exec web sh
flask db migrate -m <summary_of_changes>
```

This will generate a migration file under `/web/migrations/versions`. You will likely need to edit the generated 
commands. This file should be committed to version control and can be applied by running
```shell
flask db upgrade
```

A full list of Alembic commands is given [here.](https://flask-migrate.readthedocs.io/en/latest/)

### Seed data
Seed data is generated by the Python script in `web/app/seed/app_seed.py`.


## Hasura
### Web Interface
Hasura provides the bulk of the GraphQL interface. Once the container is running, you can access the web interface at
`localhost:8080`. 

### Committing Changes
After you've made changes to Hasura, export the metadata using the command `./commands/exporthasura` and commit the
metadata to version control.  The metadata is exported to the folder `graphql/metadata`. Note you can also work in the
reverse fashion if you prefer to edit .yaml files directly instead of using the web interface. In this case, after
you've made your changes to the .yaml files, you can run `./commands/importhasura` to load in the new metadata.

In your version control commit, also commit the `schema.graphql` file generated from `./commands/gqschema` that serves
as our GraphQL documentation for Hasura.


## Dependencies
Python dependencies are managed by Pipenv. However, Pipenv has been less than ideal, so we'll likely be switching away.
In the meantime, so add a new dependency, run
```shell
./commands/updatepip <name_of_new_library>
```
Note this only works for adding one library at a time, and it is painfully slow.
GCP also only accepts `requirements.txt` files, so new dependencies must be added there as well. If you're planning
on adding another dependency, it may be worth looking into switching to a new package manager altogether.


## Testing
Unit tests are located in `/web/test/unit`. The folder structure here should mirror that of `/web/app`.
To run a test, you can use any one of the following commands.
```shell
# Run all unit tests
./commands/runtests unit

# Run a specific file
./commands/runtests unit/models/test_chat.py

# Run a specific test
./commands/runtests unit/models/test_chat.py::test_chat_num_unread__whenNoMessagesInChat
```

Tests use an ephemeral test database spun up by Docker.


## Deployment
If you added new environment variables for the Flask API in `web`, then you will need to add those as new secrets
to the `WEB_ENV_VARIABLES_YAML` and possibly the `ENV_WEB_DEPLOY` secrets in GitHub Actions.  For PR checks, you
may also need to add them in `.env.db_test`.

If you added new environment variables for Hasura, you will need manually deploy those to AppEngine to prevent
horizontal scaling issues concerning stale or cached data. Note you must add them in a backwards compatible manner
so that the current code running in production still works (i.e. you can't remove or rename variables until after your
metadata changes have been deployed). The new metadata will be applied by the `deploy-appengine` GitHub action.
Do not deploy the new metadata until all Hasura instances have been upgraded to the latest version.

An example of horizontal scaling issues.  If you removed an environment variable in Hasura and didn't wait until
all instances had upgraded to the latest version to deploy your metadata, then the new instances will work but the old 
instances will bug out on trying to process the new metadata since an environment variable the depended on is missing.

If you updated the Hasura version, you must manually deploy the new Dockerfile to AppEngine and update the version of
the CLI tool used in the `deploy-appengine` GitHub action.

One possible situation to keep an eye out for is if, when Hasura reloads its metadata, it does not get the latest
GraphQL schema from the Flask API since it called an instance running an old version. Really, this process should be
improved so that it only pulls from the latest version, whether that means specifying the version manually or waiting
until all traffic has been migrated (no more traffic split).

GitHub Actions uses base64 encoded secrets except for `GCP_SA_KEY`. Create them as follows.
```shell
base64 -i <file>
```


## Integrations (Optional)
### Zoom
 - Create a Zoom account
 - Go to settings, enable "Allow No-Passphrase Cloud Recording Viewings"
 - Set API token as env variable ZOOM_JWT

### Google Calendar
 - Create a Google account
 - Add calendar abilities (see gcal project)
 - Create https://currents.google.com/ profile so that name shows up correctly on notifications
 - Set API token as env variable GCAL_TOKEN